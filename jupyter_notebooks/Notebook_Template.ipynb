{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **(Title Change)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Write your notebook objective here, for example, \"Fetch data from Kaggle and save as raw data\", or \"engineer features for modelling\"\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Write down which data or information you need to run the notebook \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artefacts you generate by the end of the notebook \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* If you have any additional comments that don't fit in the previous bullets, please state them here. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/mahahussain/Desktop'"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/mahahussain'"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1: ETL Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Extract: Importing Libraries, Extracting & Describing the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- This section involves importing libraries necessary for subsequent data analysis and visualisation tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These libraries are imported to handle data manipulation (pandas, numpy), create visualisations (seaborn, matplotlib, plotly), and perform statistical analysis (scipy.stats)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importing necessary libraries for data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import scipy.stats as st"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We opted to access the CSV file, Online Retail.csv, directly from a GitHub repository using the raw URL of the file. \n",
        "\n",
        "By using this method, the CSV file is fetched directly from the GitHub repository without needing to download it manually, making the process efficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Storing the url of the dataset and storing it in a DataFrame\n",
        "url = \"https://raw.githubusercontent.com/bvhadra/Online_Retail_Sales_Analysis/refs/heads/main/Online%20Retail.csv\"\n",
        "df = pd.read_csv(url) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  InvoiceNo StockCode                          Description  Quantity  \\\n",
            "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
            "1    536365     71053                  WHITE METAL LANTERN         6   \n",
            "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
            "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
            "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
            "\n",
            "           InvoiceDate  UnitPrice  CustomerID         Country  \n",
            "0  2010-12-01 08:26:00       2.55       17850  United Kingdom  \n",
            "1  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
            "2  2010-12-01 08:26:00       2.75       17850  United Kingdom  \n",
            "3  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
            "4  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n"
          ]
        }
      ],
      "source": [
        "# Display the first few rows of the DataFrame to confirm successful import\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       InvoiceNo StockCode                      Description  Quantity  \\\n",
            "541904    581587     22613      PACK OF 20 SPACEBOY NAPKINS        12   \n",
            "541905    581587     22899     CHILDREN'S APRON DOLLY GIRL          6   \n",
            "541906    581587     23254    CHILDRENS CUTLERY DOLLY GIRL          4   \n",
            "541907    581587     23255  CHILDRENS CUTLERY CIRCUS PARADE         4   \n",
            "541908    581587     22138    BAKING SET 9 PIECE RETROSPOT          3   \n",
            "\n",
            "                InvoiceDate  UnitPrice  CustomerID Country  \n",
            "541904  2011-12-09 12:50:00       0.85       12680  France  \n",
            "541905  2011-12-09 12:50:00       2.10       12680  France  \n",
            "541906  2011-12-09 12:50:00       4.15       12680  France  \n",
            "541907  2011-12-09 12:50:00       4.15       12680  France  \n",
            "541908  2011-12-09 12:50:00       4.95       12680  France  \n"
          ]
        }
      ],
      "source": [
        "# Display the last few rows of the DataFrame to confirm successful import\n",
        "print(df.tail())  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then used the `df.describe()` function to generate a summary of key statistics for the numerical columns, helping us understand the data's distribution and identify potential outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quantity</th>\n",
              "      <th>UnitPrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>541909.000000</td>\n",
              "      <td>541909.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>9.552250</td>\n",
              "      <td>4.611114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>218.081158</td>\n",
              "      <td>96.759853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-80995.000000</td>\n",
              "      <td>-11062.060000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.080000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>80995.000000</td>\n",
              "      <td>38970.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Quantity      UnitPrice\n",
              "count  541909.000000  541909.000000\n",
              "mean        9.552250       4.611114\n",
              "std       218.081158      96.759853\n",
              "min    -80995.000000  -11062.060000\n",
              "25%         1.000000       1.250000\n",
              "50%         3.000000       2.080000\n",
              "75%        10.000000       4.130000\n",
              "max     80995.000000   38970.000000"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generates a summary of statistics (count, mean, std, min, max, etc.) for numerical columns in the DataFrame.\n",
        "df[['Quantity', 'UnitPrice']].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Findings:\n",
        "\n",
        "**Count**: Both **Quantity** and **UnitPrice** have 500k+ non-null entries, indicating a large dataset. Given our technical limitations, we will need to truncate this data.\n",
        "\n",
        "1. **Mean**: The average **Quantity** is 9.55, and the average **UnitPrice** is 4.61, providing insight into typical values for these columns.\n",
        "\n",
        "2. **Standard Deviation**: The standard deviations (218.08 for **Quantity** and 96.76 for **UnitPrice**) show significant variability in both columns, suggesting that the data includes a wide spread of values.\n",
        "\n",
        "**Min/Max**: The extreme values are notable:\n",
        "1. The **Quantity** column includes a minimum of **-80,995** and a maximum of **80,995**, with negative quantities being particularly concerning.\n",
        "\n",
        "2. Similarly, the **UnitPrice** has a negative minimum of **-11,062.06** and a maximum of **38,970**, indicating the presence of abnormal negative values for prices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We started by inspecting the counts of the null/not-null values in the columns using `df.count()` and `df.isna()` respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Count of non-NA values in each column:\n",
            "InvoiceNo      541909\n",
            "StockCode      541909\n",
            "Description    540455\n",
            "Quantity       541909\n",
            "InvoiceDate    541909\n",
            "UnitPrice      541909\n",
            "CustomerID     541909\n",
            "Country        541909\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Display the count of non null values in each column\n",
        "print(\"\\nCount of non-NA values in each column:\")\n",
        "print(df.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Missing values in each column:\n",
            "InvoiceNo         0\n",
            "StockCode         0\n",
            "Description    1454\n",
            "Quantity          0\n",
            "InvoiceDate       0\n",
            "UnitPrice         0\n",
            "CustomerID        0\n",
            "Country           0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values in each column\n",
        "print(\"\\nMissing values in each column:\")\n",
        "print(df.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset has no missing values in most columns, except for **Description**, which contains 1,454 missing entries. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Next Steps:\n",
        "\n",
        "Following the extraction stage, we will be addressing the following key issues:\n",
        "\n",
        "1. **Negative Values**: We need to look into the negative values found in both **Quantity** and **UnitPrice**, especially the extreme ones, as they could be errors or invalid entries. These might be caused by mistakes in data entry, returns, or system glitches.\n",
        "\n",
        "2. **Clean the Data**: We will remove or correct the negative values in both columns, making sure only valid positive numbers are used in the analysis.\n",
        "\n",
        "3. **Outlier Detection**: We’ll also need to deal with the extreme outliers in **Quantity** and **UnitPrice**. \n",
        "\n",
        "4. **Feature Engineering**: We will also perform feature engineering to ensure that the name column is properly standardised, especially since some items have the same name but come in different colours (e.g., \"WHITE HANGING HEART T-LIGHT HOLDER\" in different colorus). This will help avoid confusion and ensure consistency.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Transform: Data pre-processing & Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- This section involves cleaning the data, removing missing and invalid values. It also includes feature engineering and truncation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2.1 Filtering the data for the UK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Following the request from our stakeholders, we will focus exclusively on the United Kingdom (UK) for the analysis.\n",
        "\n",
        "First, we want to confirm that the United Kingdom does not have any alternate names in the data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique values in 'Country' column: ['United Kingdom' 'France' 'Australia' 'Netherlands' 'Germany' 'Norway'\n",
            " 'EIRE' 'Switzerland' 'Spain' 'Poland' 'Portugal' 'Italy' 'Belgium'\n",
            " 'Lithuania' 'Japan' 'Iceland' 'Channel Islands' 'Denmark' 'Cyprus'\n",
            " 'Sweden' 'Austria' 'Israel' 'Finland' 'Bahrain' 'Greece' 'Hong Kong'\n",
            " 'Singapore' 'Lebanon' 'United Arab Emirates' 'Saudi Arabia'\n",
            " 'Czech Republic' 'Canada' 'Unspecified' 'Brazil' 'USA'\n",
            " 'European Community' 'Malta' 'RSA']\n"
          ]
        }
      ],
      "source": [
        "# Check unique values in the Country column\n",
        "unique_countries = df['Country'].unique()\n",
        "print(\"Unique values in 'Country' column:\", unique_countries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Having confirmed this, we will now filter the data accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique values in 'Country' column after filtering: ['United Kingdom']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Filter the dataset to include only the United Kingdom\n",
        "df_uk = df[df['Country'] == 'United Kingdom']\n",
        "\n",
        "# Verify the filter by checking the unique countries again\n",
        "unique_countries_after_filter = df_uk['Country'].unique()\n",
        "print(\"Unique values in 'Country' column after filtering:\", unique_countries_after_filter)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will now begin to inspect the now filtered data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First few rows of the data:\n",
            "  InvoiceNo StockCode                          Description  Quantity  \\\n",
            "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
            "1    536365     71053                  WHITE METAL LANTERN         6   \n",
            "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
            "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
            "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
            "\n",
            "           InvoiceDate  UnitPrice  CustomerID         Country  \n",
            "0  2010-12-01 08:26:00       2.55       17850  United Kingdom  \n",
            "1  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
            "2  2010-12-01 08:26:00       2.75       17850  United Kingdom  \n",
            "3  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
            "4  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n"
          ]
        }
      ],
      "source": [
        "# Display the first few rows of the DataFrame to get an overview.\n",
        "print(\"First few rows of the data:\")\n",
        "print(df_uk.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Summary statistics for numerical columns:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quantity</th>\n",
              "      <th>UnitPrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>495478.000000</td>\n",
              "      <td>495478.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.605486</td>\n",
              "      <td>4.532422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>227.588756</td>\n",
              "      <td>99.315438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-80995.000000</td>\n",
              "      <td>-11062.060000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>80995.000000</td>\n",
              "      <td>38970.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Quantity      UnitPrice\n",
              "count  495478.000000  495478.000000\n",
              "mean        8.605486       4.532422\n",
              "std       227.588756      99.315438\n",
              "min    -80995.000000  -11062.060000\n",
              "25%         1.000000       1.250000\n",
              "50%         3.000000       2.100000\n",
              "75%        10.000000       4.130000\n",
              "max     80995.000000   38970.000000"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Summary statistics for numerical columns\n",
        "print(\"\\nSummary statistics for numerical columns:\")\n",
        "df_uk[['Quantity', 'UnitPrice']].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2.2 Removing Null Rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Count of non-NA values in each column:\n",
            "InvoiceNo      495478\n",
            "StockCode      495478\n",
            "Description    494024\n",
            "Quantity       495478\n",
            "InvoiceDate    495478\n",
            "UnitPrice      495478\n",
            "CustomerID     495478\n",
            "Country        495478\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Display the count of non null values in each column\n",
        "print(\"\\nCount of non-NA values in each column:\")\n",
        "print(df_uk.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Missing values in each column:\n",
            "InvoiceNo         0\n",
            "StockCode         0\n",
            "Description    1454\n",
            "Quantity          0\n",
            "InvoiceDate       0\n",
            "UnitPrice         0\n",
            "CustomerID        0\n",
            "Country           0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nMissing values in each column:\")\n",
        "print(df_uk.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2.3 Truncating the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In terms of technical feasibility, truncating the dataset was a necessary decision. The full filtered dataset for the UK subset contains upwards of 400,000 records.\n",
        "\n",
        "This reduction in size will allow us to focus on a representative sample of the data and ensure that the analysis remains efficient, whilst aligning with the stakeholder requirements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8000, 8)\n",
            "  InvoiceNo StockCode                          Description  Quantity  \\\n",
            "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
            "1    536365     71053                  WHITE METAL LANTERN         6   \n",
            "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
            "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
            "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
            "\n",
            "           InvoiceDate  UnitPrice  CustomerID         Country  \n",
            "0  2010-12-01 08:26:00       2.55       17850  United Kingdom  \n",
            "1  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
            "2  2010-12-01 08:26:00       2.75       17850  United Kingdom  \n",
            "3  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
            "4  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n"
          ]
        }
      ],
      "source": [
        "df_truncated = df_uk.head(8000)\n",
        "\n",
        "# Verifies the truncation\n",
        "print(df_truncated.shape)\n",
        "print(df_truncated.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Having previously ascertained that the only missing values in the dataset were in the **Description** column, we can delete those particular rows. \n",
        "\n",
        "The rationale behind this decision mainly lies in the fact that our stakeholder wishes to gather insights on product trends, null values for product names will be unhelpful for this analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values in 'Description' column before: 42\n",
            "Shape before deletion: (8000, 8)\n"
          ]
        }
      ],
      "source": [
        "missing_before = df_truncated['Description'].isna().sum()\n",
        "print(\"Missing values in 'Description' column before:\", missing_before)\n",
        "\n",
        "# Delete rows with missing values in 'Description'\n",
        "df_truncated_cleaned = df_truncated.dropna(subset=['Description'])\n",
        "print(f\"Shape before deletion: {df_truncated.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values in 'Description' after deletion: 0\n",
            "Shape after deletion: (7958, 8)\n"
          ]
        }
      ],
      "source": [
        "# Check the count of missing values in 'Description' after deletion\n",
        "missing_after = df_truncated_cleaned['Description'].isna().sum()\n",
        "print(f\"Missing values in 'Description' after deletion: {missing_after}\")\n",
        "\n",
        "print(f\"Shape after deletion: {df_truncated_cleaned.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Remaining null values in the dataset:\n",
            "InvoiceNo      0\n",
            "StockCode      0\n",
            "Description    0\n",
            "Quantity       0\n",
            "InvoiceDate    0\n",
            "UnitPrice      0\n",
            "CustomerID     0\n",
            "Country        0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check for any remaining NA values in the dataset\n",
        "na_check = df_truncated_cleaned.isna().sum()\n",
        "print(\"Remaining null values in the dataset:\")\n",
        "print(na_check)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2.4 Transforming invalid inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- remove neg price and qty? why? b/c can't buy 0 items.. + can't pay negative\n",
        "\n",
        "- some rows contain neg, likely indicates data entry error or anomaly w/ transactiosns\n",
        "\n",
        "for purpose of this analysis and tp prvent skewed results and to ensure data integrity - removing these rwos.\n",
        "\n",
        "unknown if returns or refunds, "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2.5 Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- break down invoice date into year, month, day, time\n",
        "- create new col revenue total per item purchase, \n",
        "- create new col revenue per year, month, day\n",
        "- break items into categories and colour? dep. on num of unique values...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2.6 Loading data into new csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2 : VISUALISATIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test\n"
          ]
        }
      ],
      "source": [
        "print(\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In cases where you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "expected an indented block after 'try' statement on line 2 (553063055.py, line 5)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    except Exception as e:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'try' statement on line 2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "  # create your folder here\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python Virtual Env (.venv)",
      "language": "python",
      "name": ".venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
